{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SPARK_LOCAL_IP\"] = \"127.0.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, DateType, TimestampType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.0.0\") \\\n",
    "        .config('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider')\\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", 'AKIA3AEXDSNEGXQERCGG') \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", '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') \\\n",
    "        .appName('Report 1 : Operations Management Report')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsSchema = StructType([\n",
    "    StructField(\"Id\", IntegerType(), True),\n",
    "    StructField(\"Status\", StringType(), True),\n",
    "    StructField(\"BoardId\", IntegerType(), True),\n",
    "    StructField(\"BatchId\", StringType(), True),\n",
    "    StructField(\"WorkOrderId\", StringType(), True),\n",
    "    StructField(\"RoutingStageId\", StringType(), True),\n",
    "    StructField(\"RoutingStageName\", StringType(), True),\n",
    "    StructField(\"Operator\", StringType(), True),\n",
    "    StructField(\"Deviation\", StringType(), True),\n",
    "    StructField(\"InspectionDate\", StringType(), True),\n",
    "    StructField(\"LastModifiedDate\", StringType(), True),\n",
    "    StructField(\"ReInspectionNeeded\", StringType(), True),\n",
    "    StructField(\"PreviouslySannedBoards\", StringType(), True),\n",
    "    StructField(\"RoutingStatus\", StringType(), True),\n",
    "    StructField(\"CavityID\", StringType(), True),\n",
    "    StructField(\"SubWorkCenter\", StringType(), True),\n",
    "    StructField(\"StationCode\", StringType(), True),\n",
    "    StructField(\"StationName\", StringType(), True),\n",
    "    StructField(\"TrayId\", StringType(), True),\n",
    "    StructField(\"AssetSubNodeId\", StringType(), True),\n",
    "    StructField(\"CollectionId\", StringType(), True),\n",
    "    StructField(\"Company\", StringType(), True),\n",
    "    StructField(\"Division\", StringType(), True),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workOrdersSchema=StructType([\n",
    "    StructField(\"Id\", StringType(), True),\n",
    "    StructField(\"ItemId\", StringType(), True),\n",
    "    StructField(\"LineNo\", StringType(), True),\n",
    "    StructField(\"Description\", StringType(), True),\n",
    "    StructField(\"Quantity\", StringType(), True),\n",
    "    StructField(\"Started\", StringType(), True),\n",
    "    StructField(\"StartDate\", StringType(), True),\n",
    "    StructField(\"EndDate\", StringType(), True),\n",
    "    StructField(\"EcnNo\", StringType(), True),\n",
    "    StructField(\"EcnQunatity\", StringType(), True),\n",
    "    StructField(\"EcnStatus\", StringType(), True),\n",
    "    StructField(\"ProductRevision\", StringType(), True),\n",
    "    StructField(\"PlannedStartDate\", StringType(), True),\n",
    "    StructField(\"PlannedEndDate\", StringType(), True),\n",
    "    StructField(\"Isblocked\", StringType(), True),\n",
    "    StructField(\"BlockedDate\", StringType(), True),\n",
    "    StructField(\"BlockedBy\", StringType(), True),\n",
    "    StructField(\"BatchProceedStatus\", StringType(), True),\n",
    "    StructField(\"WorkOrderClosureStatus\", StringType(), True),\n",
    "    StructField(\"ShortClosedQuantity\", StringType(), True),\n",
    "    StructField(\"CreationDate\", StringType(), True),\n",
    "    StructField(\"DysonPONumber\", StringType(), True),\n",
    "    StructField(\"CustomerSKUNumber\", StringType(), True),\n",
    "    StructField(\"RoutingVersionId\", StringType(), True),\n",
    "    StructField(\"RoutingHeaderId\", StringType(), True),\n",
    "    StructField(\"ERPClosureStatus\", StringType(), True),\n",
    "    StructField(\"FeederReloadLockRequired\", StringType(), True),\n",
    "    StructField(\"MSDLockRequired\", StringType(), True),\n",
    "    StructField(\"Unit Price\", StringType(), True),\n",
    "    StructField(\"AllowCustomerRefNoRepetition\", StringType(), True),\n",
    "    StructField(\"Company\", StringType(), True),\n",
    "    StructField(\"Division\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour\n",
    "from pyspark.sql.functions import date_format\n",
    "from pyspark.sql.functions import countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plans_df = spark.read\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .option(\"delimiter\",\"|\")\\\n",
    "    .load(\"s3a://hackathon2023/data/OperationsManagement/PlansShiftWise/PlansShiftWise.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = spark.read\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"header\",\"False\")\\\n",
    "    .schema(resultsSchema)\\\n",
    "    .option(\"delimiter\",\",\")\\\n",
    "    .load(\"s3a://hackathon2023/data/OperationsManagement/Results/Results.csv\",inferSchema=True)\n",
    "routing_df = spark.read\\\n",
    "    .parquet(\"s3a://hackathon2023/data/OperationsManagement/RoutingStages/RoutingStages.parquet\",inferSchema=True)\n",
    "combined_df = results_df\\\n",
    "    .join(routing_df, [results_df.RoutingStageId == routing_df.id,results_df.WorkOrderId==routing_df.WorkOrderId], \"inner\")\\\n",
    "    .drop(routing_df.WorkOrderId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_orders_df = spark.read\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"header\",\"false\")\\\n",
    "    .option(\"delimiter\",\"\\t\")\\\n",
    "    .schema(workOrdersSchema)\\\n",
    "    .load(\"s3a://hackathon2023/data/OperationsManagement/Workorders/Workorders.csv\",inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df\\\n",
    "    .join(work_orders_df, combined_df.WorkOrderId == work_orders_df.Id, \"left_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df\\\n",
    "    .filter(combined_df.Surface == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_df = combined_df.groupBy(\"ItemId\", \"SubWorkCenter\", \n",
    "                                hour(combined_df.LastModifiedDate).alias(\"Hour\"), \n",
    "                                date_format(combined_df.LastModifiedDate, \"yyyy-MM-dd\").alias(\"Date\")\n",
    "                               ).agg(countDistinct(\"BoardId\").alias(\"ActualQuantity\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = actual_df.join(plans_df, \n",
    "                             (actual_df.ItemId == plans_df.ItemNo) & \n",
    "                             (actual_df.SubWorkCenter == plans_df.Station) & \n",
    "                             (actual_df.Hour == hour(plans_df.Hour)) & \n",
    "                             (actual_df.Date == date_format(plans_df.Date, \"yyyy-MM-dd\")), \n",
    "                             \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df=spark.read\\\n",
    "    .text(\"s3a://hackathon2023/data/OperationsManagement/Items/Items.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import re\n",
    "from pyspark.sql.functions import udf,col,struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"C[0-9]+(.+?)UU-(.+?)nxklh2022(.+?)-.+?1(.+?)\\\\R\\$\\$(.+?)plantxi12(.+?)(?:(?:\\d{2}){1,2}[/-]\\d{1,2}[/-](?:\\d{2}){1,2})\\s\\d{1,2}:\\d{2}:\\d{2}(.+?)k8(.+?)bHM(.+?)--(.+?)P011(.+?)MD(.+)\"\n",
    "schema = StructType([\n",
    "    StructField(\"ID\", StringType(), True),\n",
    "    StructField(\"Description\", StringType(), True),\n",
    "    StructField(\"Modality\", StringType(), True),\n",
    "    StructField(\"Revision\", StringType(), True),\n",
    "    StructField(\"BaseUOM\", StringType(), True),\n",
    "    StructField(\"Batch_Management\", StringType(), True),\n",
    "    StructField(\"SerialNumber_Profile\", StringType(), True),\n",
    "    StructField(\"ShelfLife\", StringType(), True),\n",
    "    StructField(\"ShelfLife_Date\", StringType(), True),\n",
    "    StructField(\"MSD\", StringType(), True),\n",
    "    StructField(\"Item_Category\", StringType(), True),\n",
    "    StructField(\"MSLDetails\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values(s):\n",
    "    m = re.match(pattern, s)\n",
    "    if m:\n",
    "        return tuple(m.groups())\n",
    "    else:\n",
    "        return None\n",
    "extract_values_udf = udf(extract_values, schema)\n",
    "items_df = items_df\\\n",
    "    .withColumn(\"structured_data\", extract_values_udf(items_df.value))\n",
    "items_df = items_df\\\n",
    "    .withColumn(\"ID\", col(\"structured_data.ID\"))\n",
    "items_df = items_df\\\n",
    "    .withColumn(\"Description\", col(\"structured_data.Description\"))\n",
    "items_df = items_df\\\n",
    "    .withColumn(\"Modality\", col(\"structured_data.Modality\"))\n",
    "items_df = items_df\\\n",
    "    .withColumn(\"Revision\", col(\"structured_data.Revision\"))\n",
    "items_df = items_df\\\n",
    "    .withColumn(\"BaseUOM\", col(\"structured_data.BaseUOM\"))\n",
    "items_df = items_df\\\n",
    "    .withColumn(\"Batch_Management\", col(\"structured_data.Batch_Management\"))\n",
    "items_df = items_df\\\n",
    "    .withColumn(\"SerialNumber_Profile\", col(\"structured_data.SerialNumber_Profile\"))\n",
    "items_df = items_df\\\n",
    "    .withColumn(\"ShelfLife\", col(\"structured_data.ShelfLife\"))\n",
    "items_df = items_df\\\n",
    "    .withColumn(\"ShelfLife_Date\", col(\"structured_data.ShelfLife_Date\"))\n",
    "items_df = items_df\\\n",
    "    .withColumn(\"MSD\", col(\"structured_data.MSD\"))\n",
    "items_df = items_df\\\n",
    "    .withColumn(\"Item_Category\", col(\"structured_data.Item_Category\"))\n",
    "items_df = items_df\\\n",
    "    .withColumn(\"MSLDetails\", col(\"structured_data.MSLDetails\"))\n",
    "items_df = items_df\\\n",
    "    .withColumn(\"MSLDetails\", col(\"structured_data.MSLDetails\"))\n",
    "items_df = items_df\\\n",
    "    .drop(\"value\")\n",
    "items_df = items_df\\\n",
    "    .drop(\"structured_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = combined_df\\\n",
    "    .join(items_df, combined_df.ItemId == items_df.ID, \"left_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
