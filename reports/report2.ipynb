{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObkZth5YP5OH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pyspark.sql.functions import datediff,current_date,to_date,date_format,count,col,when\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, DateType, TimestampType, DoubleType\n",
        "from pyspark.sql.types import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60TEaxl3P5OJ"
      },
      "outputs": [],
      "source": [
        "os.environ[\"SPARK_LOCAL_IP\"] = \"127.0.0.1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMJ7Kp3lP5OL"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.0.0\") \\\n",
        "        .config('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider')\\\n",
        "        .config(\"spark.hadoop.fs.s3a.access.key\", 'AKIA3AEXDSNEGXQERCGG') \\\n",
        "        .config(\"spark.hadoop.fs.s3a.secret.key\", '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') \\\n",
        "        .appName('Report 2 : SC Supply Chain Report')\\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roXOe-y9P5ON"
      },
      "outputs": [],
      "source": [
        "itemSchema = StructType([\n",
        "    StructField(\"No\", StringType(), True),\n",
        "    StructField(\"No_ 2\", StringType(), True),\n",
        "    StructField(\"Description\", StringType(), True),\n",
        "    StructField(\"Search Description\", StringType(), True),\n",
        "    StructField(\"Description 2\", StringType(), True),\n",
        "    StructField(\"Base Unit of Measure\", StringType(), True),\n",
        "    StructField(\"Price Unit Conversion\", StringType(), True),\n",
        "    StructField(\"Type\", StringType(), True),\n",
        "    StructField(\"Inventory Posting Group\", StringType(), True),\n",
        "    StructField(\"Shelf No_\", StringType(), True),\n",
        "    StructField(\"Item Disc_ Group\", StringType(), True),\n",
        "    StructField(\"Allow Invoice Disc_\", StringType(), True),\n",
        "    StructField(\"Statistics Group\", StringType(), True),\n",
        "    StructField(\"Commission Group\", StringType(), True),\n",
        "    StructField(\"Unit Price\", IntegerType(), True),\n",
        "    StructField(\"Price_Profit Calculation\", StringType(), True),\n",
        "    StructField(\"Profit _\", StringType(), True),\n",
        "    StructField(\"Costing Method\", StringType(), True),\n",
        "    StructField(\"Unit Cost\", StringType(), True),\n",
        "    StructField(\"Standard Cost\", StringType(), True),\n",
        "    StructField(\"Quoted Price(INR)\", StringType(), True),\n",
        "    StructField(\"Quoted Price(FCY)\", StringType(), True),\n",
        "    StructField(\"Quoted Currency\", StringType(), True),\n",
        "    StructField(\"Standard Cost_\", StringType(), True),\n",
        "    StructField(\"Production_BOM_No\", StringType(), True),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WFeCSkaP5OP"
      },
      "outputs": [],
      "source": [
        "item_df = spark.read.parquet(\"s3a://hackathon2023/data/SCSupplyChain/item/item.parquet\", inferSchema=True)\n",
        "bronze_item_df = item_df\n",
        "for col in item_df.columns:\n",
        "    item_df = item_df.withColumnRenamed(col, [f.name for f in itemSchema.fields if f.name != col][0])\n",
        "item_df = spark.createDataFrame(item_df.rdd, itemSchema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLuAwXuIGx6Y"
      },
      "outputs": [],
      "source": [
        "item_df=item_df.drop('No_ 2')\n",
        "item_df=item_df.drop('Description 2')\n",
        "item_df=item_df.drop('Search Description')\n",
        "item_df=item_df.drop('Type')\n",
        "item_df=item_df.na.drop()\n",
        "silver_item_df = item_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ne6sPJJPP5OQ"
      },
      "outputs": [],
      "source": [
        "warehouseSchema=StructType([\n",
        "    StructField(\"Entry No\", StringType(), True),\n",
        "    StructField(\"Journal Batch Name\", StringType(), True),\n",
        "    StructField(\"Line No_\", StringType(), True),\n",
        "    StructField(\"Registering Date\", StringType(), True),\n",
        "    StructField(\"Location Code\", StringType(), True),\n",
        "    StructField(\"Zone Code\", StringType(), True),\n",
        "    StructField(\"Bin Code\", StringType(), True),\n",
        "    StructField(\"Description\", StringType(), True),\n",
        "    StructField(\"Item No_\", StringType(), True),\n",
        "    StructField(\"Quantity\", StringType(), True),\n",
        "    StructField(\"Qty_ (Base)\", StringType(), True),\n",
        "    StructField(\"Source Type\", StringType(), True),\n",
        "    StructField(\"Source Subtype\", StringType(), True),\n",
        "    StructField(\"Source No_\", StringType(), True),\n",
        "    StructField(\"Source Line No_\", StringType(), True),\n",
        "    StructField(\"Source Subline No_\", StringType(), True),\n",
        "    StructField(\"Source Document\", StringType(), True),\n",
        "    StructField(\"Source Code\", StringType(), True),\n",
        "    StructField(\"Reason Code\", StringType(), True),\n",
        "    StructField(\"No_ Series\", StringType(), True),\n",
        "    StructField(\"Bin Type Code\", StringType(), True),\n",
        "    StructField(\"Cubage\", StringType(), True),\n",
        "    StructField(\"Weight\", StringType(), True),\n",
        "    StructField(\"Journal Template Name\", StringType(), True),\n",
        "    StructField(\"Whse_ Document No_\", StringType(), True),\n",
        "    StructField(\"Whse_ Document Type\", StringType(), True),\n",
        "    StructField(\"Whse_ Document Line No_\", StringType(), True),\n",
        "    StructField(\"Entry Type\", StringType(), True),\n",
        "    StructField(\"Reference Document\", StringType(), True),\n",
        "    StructField(\"Reference No_\", StringType(), True),\n",
        "    StructField(\"User ID\", StringType(), True),\n",
        "    StructField(\"Variant Code\", StringType(), True),\n",
        "    StructField(\" Qty_ per Unit of Measure\", StringType(), True),\n",
        "    StructField(\"Unit of Measure Code\", StringType(), True),\n",
        "    StructField(\"Serial No_\", StringType(), True),\n",
        "    StructField(\"Lot No_\", StringType(), True),\n",
        "    StructField(\"Warranty Date\", StringType(), True),\n",
        "    StructField(\"Expiration Date\", StringType(), True),\n",
        "    StructField(\"Phys Invt Counting Period Code\", StringType(), True),\n",
        "    StructField(\"Phys Invt Counting Period Type\", StringType(), True),\n",
        "    StructField(\"Dedicated\", StringType(), True),\n",
        "    StructField(\"Company\", StringType(), True),\n",
        "    StructField(\"Division\", StringType(), True),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3djQEnOOP5OR"
      },
      "outputs": [],
      "source": [
        "warehouse_df=spark.read.format(\"csv\").option(\"header\", \"false\").option(\"delimiter\",\",\").schema(warehouseSchema).load(\"s3a://hackathon2023/data/SCSupplyChain/warehouse/warehouse.csv\")\n",
        "bronze_warehousedf = warehouse_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZqT2TLzP5OS"
      },
      "outputs": [],
      "source": [
        "warehouse_df = warehouse_df.withColumn(\"Registering Date\", to_date(warehouse_df[\"Registering Date\"], \"dd-MM-yyyy\"))\n",
        "warehouse_df=warehouse_df.drop('Journal Batch Name')\n",
        "warehouse_df=warehouse_df.drop('Reason Code')\n",
        "warehouse_df=warehouse_df.drop('Journal Template Name')\n",
        "warehouse_df=warehouse_df.drop('Variant Code')\n",
        "warehouse_df=warehouse_df.drop('Serial No_')\n",
        "warehouse_df=warehouse_df.drop('Company')\n",
        "warehouse_df=warehouse_df.drop('Division')\n",
        "warehouse_df=warehouse_df.drop('Qty_ (Base)')\n",
        "silver_warehousedf = warehouse_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwcMKAKwP5OU"
      },
      "outputs": [],
      "source": [
        "production_df=spark.read.format(\"csv\").option(\"header\",\"True\").option(\"delimiter\",\"\\t\").load(\"s3a://hackathon2023/data/SCSupplyChain/production/production.txt\")\n",
        "bronze_productiondf = production_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLkAwvXFGvCG"
      },
      "outputs": [],
      "source": [
        "production_df=production_df.drop('Version Code')\n",
        "production_df=production_df.drop('Position 2')\n",
        "production_df=production_df.drop('Position 3')\n",
        "production_df=production_df.drop('Company')\n",
        "production_df=production_df.drop('Division')\n",
        "production_df=production_df.na.drop()\n",
        "silver_productiondf = production_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Mhn5ZXWP5OU"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession, functions as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbyCJPjJP5OU"
      },
      "outputs": [],
      "source": [
        "df_1 = warehouse_df.groupBy(\"Lot No_\", \"Bin Code\", \"Item No_\",\"Registering Date\").agg(\n",
        "    F.min(\"Registering Date\").alias(\"min_registering_date\"),\n",
        "    F.sum(\"Quantity\").alias(\"sum_quantity\"),\n",
        "    F.first(\"Zone Code\").alias(\"first_zone_code\"),\n",
        "    F.datediff(F.current_date(), F.col(\"Registering Date\")).alias(\"date_diff\")\n",
        ").filter(\"sum_quantity > 0\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfkPhXfmP5OU"
      },
      "outputs": [],
      "source": [
        "df_2 = item_df.filter(\"Production_BOM_No != ''\").select(\"No\", \"Production_BOM_No\").union(\n",
        "    production_df.select(\"No_\", \"Production BOM No_\")\n",
        ").distinct()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlXeJ0wIP5OU"
      },
      "outputs": [],
      "source": [
        "df_3 = df_1.join(df_2, df_1[\"Item No_\"] == df_2[\"No\"], \"left\").drop(\"No\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YT8AhioUP5OV"
      },
      "outputs": [],
      "source": [
        "df_3=df_3.drop('Production_BOM_No')\n",
        "df_4 = df_3.join(item_df, df_3[\"Item No_\"] == item_df[\"No\"], \"inner\")\n",
        "df_4=df_4.drop('No')\n",
        "df_4=df_4.drop('min_registering_date')\n",
        "df_4=df_4.drop('date_diff')\n",
        "df_4=df_4.drop('first_zone_code')\n",
        "gold_df = df_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hT9KuZdfP5OV",
        "outputId": "d2361839-c096-4444-d827-fb0550b7e77f"
      },
      "outputs": [],
      "source": [
        "inventory_value_by_category = df_4.groupBy(\"Item Disc_ Group\").agg(F.sum(\"Unit Price\").alias(\"Inventory Value\")) \n",
        "inventory_value_by_category.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdKzsCjXP5OX",
        "outputId": "a3951afc-915f-40f4-c55a-37f2d4b01bec"
      },
      "outputs": [],
      "source": [
        "inventory_value_by_category = df_4.groupBy(\"Item Disc_ Group\").agg(F.sum(\"Unit Price\").alias(\"Inventory Value\"))\n",
        "top_10_categories = inventory_value_by_category.sort(\"Inventory Value\", ascending=False).limit(10)\n",
        "top_10_categories.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbDWU440P5OY",
        "outputId": "79546fa9-cf79-4f15-a673-f1f91e610af3"
      },
      "outputs": [],
      "source": [
        "df_4 = df_4.withColumn(\"Age\", datediff(current_date(), to_date(\"Registering Date\", \"yyyy-MM-dd\")))\n",
        "inventory_value_by_age = df_4.groupBy(\"Age\").agg(F.sum(\"Unit Price\").alias(\"Inventory Value\"))\n",
        "inventory_value_by_age.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYdIgZjPP5OZ",
        "outputId": "4be749bd-e015-47df-e9b1-7cf4d18a3641"
      },
      "outputs": [],
      "source": [
        "bin_value = df_4.groupBy(\"Bin Code\").agg(F.sum(\"Unit Price\").alias(\"sum(value)\")).withColumnRenamed(\"sum(value)\", \"Value\")\n",
        "bin_value.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
